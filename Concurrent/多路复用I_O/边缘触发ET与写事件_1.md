# 问  
那对于写事件而言，水平出发和边缘触发有什么区别吗？比如边缘触发写事件，内核发送缓冲区不满就触发写事件，这和水平触发有什么区别？  

# 答  
对于写事件（`EPOLLOUT`）而言，水平触发（LT）和边缘触发（ET）的区别比读事件更加“微妙”，而且如果处理不当，LT 模式更容易导致 CPU 占用率飙升到 100%。

这里的核心区别在于：**内核什么时候“提醒”你。**

---

### 1. 水平触发 (LT) 的写事件：只要能写，我就嚷嚷

在 LT 模式下，只要 **内核发送缓冲区（Kernel Send Buffer）没满**，`epoll_wait` 就会一直返回该 Socket 的可写事件。

* **特点**：极其“唠叨”。
* **后果**：如果你在代码里一直关注（Register）某个 Socket 的 `EPOLLOUT`，但你手里暂时又没有数据要发，`epoll_wait` 会立刻返回，告诉你“可以写了”。于是你的 EventLoop 就会陷入死循环：`epoll_wait` -> 发现可写 -> 没数据写 -> `epoll_wait` -> ... 这种现象被称为 **Busy Loop**。

> **LT 的正确姿势**：只有当你确实有数据要发，且一次 `send` 没发完时，才去关注 `EPOLLOUT`；一旦应用层缓冲区（Output Buffer）的数据发完了，必须**立刻注销** `EPOLLOUT`。

---

### 2. 边缘触发 (ET) 的写事件：只在“腾出空间”时通知

在 ET 模式下，内核只在 Socket 的可写状态发生 **“变化”** 时通知你一次。

* **触发时机**：
1. Socket 连接刚刚建立成功时。
2. 内核缓冲区从“满”变为“不满”的瞬间。
3. 使用 `EPOLL_CTL_MOD` 修改事件，重新关注 `EPOLLOUT` 时。


* **特点**：非常“高冷”。你收到通知后，必须**拼命地写**，直到把你想发的数据发完，或者把内核缓冲区写满（直到返回 `EAGAIN`）。

---

### 3. 两者的直观对比表格 ⚖️

| 维度 | 写事件 - 水平触发 (LT) | 写事件 - 边缘触发 (ET) |
| --- | --- | --- |
| **通知逻辑** | 发送缓冲区有空位 = 通知 | 发送缓冲区从满变不满 = 通知 |
| **CPU 风险** | 容易造成 Busy Loop（死循环） | 风险较小，对内核更友好 |
| **编程复杂度** | **较高**：需要频繁注销/注册事件 | **较高**：必须一次性写到 `EAGAIN` |
| **数据发送逻辑** | 缓冲区有数据才开启 `EPOLLOUT` | 开启后可以一直留着，但逻辑复杂 |

---

### 4. 为什么 ET 模式下“不满”不一定会触发？

你提到的“内核发送缓冲区不满就触发”其实更贴近 LT。在 ET 模式下，如果缓冲区原本就是不满的，且你已经处理过一次通知了，那么内核**不会**再次通知你，除非状态再次发生跳变。

**举个例子：**

1. **连接建立**：ET 触发一次可写，你发了 10k 数据，内核缓冲区还剩 50k 空间。
2. **后续**：你手里又有了 5k 数据。这时候 `epoll_wait` **不会**因为“不满”而提醒你。
3. **操作**：你必须主动尝试 `send`。如果 `send` 返回 `EAGAIN`，说明满了，此时你才需要等 ET 的下一次提醒（即内核把这 5k 攒着的发出去，腾出空间的瞬间）。

---

### 💡 核心设计建议

在高性能 Reactor 框架（如 muduo）中，为了规避这些复杂性，通常采取以下策略：

1. **默认不关注 `EPOLLOUT**`。
2. **直接调用 `send**`：当业务层要发数据时，先直接调用系统调用 `send`。
3. **判断结果**：
* 如果数据一次性发完了，皆大欢喜，不用管 `epoll`。
* 如果没发完（返回 `EAGAIN` 或部分发送），说明内核缓冲区满了。这时才把剩下的数据存入 **应用层 Output Buffer**，并向 `epoll` **注册（或修改）** `EPOLLOUT`。


4. **回调处理**：当 `handleWrite` 被触发时，在回调里把 Output Buffer 的数据继续发，发完后记得 **立刻注销** `EPOLLOUT`。

**你想让我为你展示一段在 LT 模式下，如何优雅地处理这种“按需注册”写事件的代码逻辑吗？**

# 问  
我还有一个问题，epoll_wait是轮询的吗？不是说遍历询问，而是以send/recv一次，即发送/接受缓冲区写满一次或者写入一次作为为处理的单位，一旦完成了一次，比如内核发送缓冲区已满但是用户定义的发送缓冲还有字节没写入，这是当然要继续关注写事件，但是send过了，那epoll_wait就要把其它关注的事件报告给其它的Channel了本轮不再关注这个已发生的写事件了对吗？把执行流中断让给其它socket

# 答  
这是一个非常深刻的底层观察。你提到的“执行流中断并让给其它 socket”其实触及了 **多路复用** 和 **Reactor 事件循环** 调度的本质。

我们可以从两个层面来拆解你的疑问：

### 1. `epoll_wait` 是轮询吗？

**结论：不是  的轮询，而是“坐等通知”。**

* **对比 `select/poll**`：它们是真正的“轮询”。每次调用，内核都要把所有关注的 fd 遍历一遍，看看谁有动静。如果关注 1 万个，就要遍历 1 万个。
* **`epoll` 的机制**：它在内核里维护了一个**就绪链表 (Ready List)**。
* 当网卡收到数据或者缓冲区变空时，硬件中断会触发内核的回调函数，内核直接把这个 fd 挂进“就绪链表”。
* `epoll_wait` 做的唯一一件事就是：看看这个链表里有没有东西。有就立刻拿走；没有就睡觉（阻塞）。
* 所以，它的效率是  的（准确说是 ），与你监听的总数无关。



---

### 2. 关于“处理单位”和“执行流出让”

你的理解非常准确。`epoll_wait` 确实是以“当前已就绪的事件集合”为单位进行处理的。

#### 流程是这样的：

1. **收集就绪事件**：`epoll_wait` 执行，内核把当前所有已经准备好的事件（比如 5 个可读、3 个可写）打包成一个数组交给用户态。
2. **挨个点名执行**：在 muduo 的 `EventLoop` 中，你会看到类似这样的代码：
```cpp
for (Channel* channel : activeChannels_) {
    channel->handleEvent(); // 执行具体的 send/recv 回调
}

```


3. **你说的情况发生了**：
* 假设处理到 `Channel A` 的写事件，它调用 `send`。
* `send` 了一部分数据，内核发送缓冲区**满了**。
* 这时，`Channel A` 的 `handleEvent()` 函数**必须结束并返回**。



#### 为什么必须返回？

正如你所说，Reactor 的核心是**非阻塞**。既然内核缓冲区满了，`send` 返回了 `EAGAIN`，`Channel A` 就不应该在原地死等。

* **出让执行流**：`Channel A` 退出后，循环会立刻处理 `Channel B`。
* **下一轮再说**：等到这一轮所有的 `activeChannels_` 都处理完了，`EventLoop` 会再次回到 `epoll_wait`。
* **重新排队**：如果此时 `Channel A` 的内核缓冲区被网卡发出去了一部分，变空了，那么在下一轮 `epoll_wait` 中，它会再次出现在就绪名单里。

---

### 3. LT 模式下的“不再关注”逻辑

你提到的“本轮不再关注这个已发生的写事件”在 **LT (水平触发)** 模式下是这样运作的：

* 如果你在 `handleEvent` 里没把数据发完，且你**依然关注** `EPOLLOUT`。
* 在下一轮 `epoll_wait` 时，由于缓冲区还有空位，内核会**立刻**再次把 `Channel A` 报给你。
* **死循环风险**：如果 `Channel A` 其实没数据要发了，但你没注销 `EPOLLOUT`，`epoll_wait` 就会没完没了地提醒你。
* **muduo 的策略**：
1. 发完数据后，立刻调用 `channel_->disableWriting()`。
2. 这底层调用的是 `epoll_ctl(MOD)`，把该 fd 对应的 `EPOLLOUT` 位清零。
3. 这样，下一轮 `epoll_wait` 就不会再跳出这个 fd 的写事件了，直到你下次又有数据要发并手动开启它。



---

### 4. 总结你的直觉

> “一旦完成了一次……本轮不再关注这个已发生的写事件了对吗？把执行流中断让给其它 socket”

你的这个直觉是 **100% 正确** 的，这正是 **公平性 (Fairness)** 的体现。

* 如果一个 `Channel` 因为数据量巨大就一直霸占着 CPU 不放，其它的连接就会超时。
* Reactor 模式通过“**只做一次系统调用，满了就走，下次再来**”的原则，保证了成千上万个连接都能得到“轮流翻牌”的机会。

---

### 💡 一个进阶的小知识

如果你用的是 **ET (边缘触发)**，这种“让出”更加彻底。哪怕内核缓冲区还有空位，只要你不重新 `MOD` 或者没有新的状态跳变，内核连下一轮都不会提醒你。

**既然你已经理解了执行流的切换，要不要聊聊“空转” (Busy Loop) 的问题？如果 `epoll_wait` 总是因为某个 fd 瞬间返回，导致 CPU 占用率到 100%，你会怎么排查？**