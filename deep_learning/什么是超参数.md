
** 超参数（Hyperparameters)**是机器学习模型在训练前需要手动设置的参数，它们不是通过数据学习得到的，而是由开发者根据经验或实验调整的。超参数直接影响模型的训练过程和性能。

---

### 超参数的作用
超参数用于控制模型的结构、训练过程以及优化方式。常见的超参数包括：

1. **学习率（Learning Rate）**：
   - 控制模型参数更新的步长。
   - 过大会导致训练不稳定，过小会导致收敛过慢。

2. **批量大小（Batch Size）**：
   - 每次更新模型参数时使用的样本数量。
   - 影响训练速度和内存占用。

3. **迭代次数（Epochs）**：
   - 整个数据集被遍历的次数。
   - 过多可能导致过拟合，过少可能导致欠拟合。

4. **正则化参数（Regularization Parameter）**：
   - 如 L1/L2 正则化的权重，用于防止过拟合。

5. **网络结构相关参数**：
   - 神经网络的层数、每层的神经元数量、激活函数等。

6. **优化器参数**：
   - 如动量（Momentum）、权重衰减（Weight Decay）等。

---

### 超参数 vs 模型参数
- **超参数**：由开发者设置，不通过数据学习。
- **模型参数**：通过训练数据学习得到，如神经网络的权重和偏置。

---

### 超参数调优
超参数的选择对模型性能至关重要，常用的调优方法包括：
1. **网格搜索（Grid Search）**：
   - 遍历所有可能的超参数组合，选择最优组合。
2. **随机搜索（Random Search）**：
   - 随机选择超参数组合，效率通常高于网格搜索。
3. **贝叶斯优化（Bayesian Optimization）**：
   - 基于概率模型选择超参数。
4. **自动化工具**：
   - 如 Hyperopt、Optuna 等。

---

### 示例
在训练神经网络时，超参数可能包括：
```python
learning_rate = 0.001
batch_size = 32
epochs = 50
hidden_units = 128
dropout_rate = 0.5
```

---

### 总结
超参数是机器学习模型的关键配置，直接影响模型的训练和性能。通过合理的调优，可以显著提升模型的表现。
